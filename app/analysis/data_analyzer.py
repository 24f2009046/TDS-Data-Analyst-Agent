"""
Data Analyzer - Analyzes data and generates a response
"""

import asyncio
import base64
import io
import re
from typing import List, Dict, Any, Optional
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import pearsonr
from sklearn.linear_model import LinearRegression

from app.llm.llm_provider import LLMProvider
from app.analysis.data_scraper import DataScraper
from app.utils.utils import get_logger

logger = get_logger(__name__)

class DataAnalyzer:
    """Main data analysis class using LLM for code generation and execution"""

    def __init__(self, llm_provider: LLMProvider):
        self.llm_provider = llm_provider
        self.data_scraper = DataScraper()
        
    async def analyze_with_llm(self, questions: str, df: Optional[pd.DataFrame], additional_files: Dict[str, bytes]) -> List[Any]:
        """
        Main method to analyze data, generate code, and execute it.
        """
        
        # Prepare the prompt for the LLM
        prompt = self._build_prompt(questions, df, additional_files)
        
        # Generate Python code from the LLM
        analysis_code = await self.llm_provider.generate_python_code(prompt)
        
        # Execute the generated code and return the result
        try:
            return await self._execute_analysis_code(analysis_code, df, additional_files, questions)
        except Exception as e:
            logger.error(f"Error during code execution: {e}")
            return await self._fallback_analysis(questions, df)

    def _build_prompt(self, questions: str, df: Optional[pd.DataFrame], additional_files: Dict[str, bytes]) -> str:
        """
        Build the prompt for the LLM based on the user's request.
        """
        prompt_parts = [
            "You are a Python data analyst assistant. Your task is to write Python code to analyze data and answer a user's questions.",
            "You have access to the following libraries: pandas as pd, numpy as np, matplotlib.pyplot as plt, io, base64, LinearRegression, pearsonr.",
            "Your code must be a single, self-contained Python script. Do not use any external files or non-standard libraries.",
            "You will be provided with a pandas DataFrame named 'df' and a dictionary of additional files named 'additional_files' (where keys are filenames and values are file contents as bytes).",
            "Your final result must be a list named 'final_answer' containing exactly four elements: a number, a string, a float, and a base-64 encoded plot as a data URI.",
            "Example of the final_answer list structure: `final_answer = [10, 'Hello World', 0.95, 'data:image/png;base64,iVBORw0KGgoAAA...']`",
            "The plot must be generated by a helper function `_save_plot_to_base64()`, which is provided to you. You simply need to call it and store the result.",
            "You must follow the instructions carefully.",
            
            f"\n### User Request:\n{questions}"
        ]
        
        if df is not None:
            prompt_parts.append(f"\n### DataFrame Info:\n{df.info(buf=io.StringIO())}")
            prompt_parts.append(f"\n### DataFrame Head:\n{df.head().to_string()}")
        else:
            prompt_parts.append("\n### DataFrame Info:\nNo DataFrame provided. You may need to scrape data from a URL if specified.")

        if additional_files:
            prompt_parts.append("\n### Additional Files Provided:")
            for filename in additional_files.keys():
                prompt_parts.append(f"- {filename}")

        return "\n".join(prompt_parts)

    async def _execute_analysis_code(self, analysis_code: str, df: Optional[pd.DataFrame], additional_files: Dict[str, bytes], questions: str) -> List[Any]:
        """
        Safely execute the LLM-generated Python code.
        """
        local_scope = {
            'pd': pd,
            'np': np,
            'plt': plt,
            'io': io,
            'base64': base64,
            'LinearRegression': LinearRegression,
            'pearsonr': pearsonr,
            'df': df,
            'additional_files': additional_files,
            'scrape_url': self.data_scraper.scrape_url, # Pass the scraper function
            '__builtins__': {
                'print': print,
                'len': len,
                'str': str,
                'float': float,
                'int': int,
                'list': list,
                'dict': dict,
                'Exception': Exception,
                'isinstance': isinstance,
                '__import__': __import__ # THIS IS THE CRUCIAL FIX.
            },
        }

        # The LLM's code is expected to define a helper function `_save_plot_to_base64`.
        def _save_plot_to_base64() -> str:
            buffer = io.BytesIO()
            plt.savefig(buffer, format='png', bbox_inches='tight', dpi=100)
            plt.close()
            img_data = buffer.getvalue()

            if len(img_data) > 99000:
                logger.warning("Plot image size exceeds 100KB. Re-generating with lower DPI.")
                plt.figure(figsize=(6, 4))
                plt.text(0.5, 0.5, "Plot size exceeded limit.", ha='center', va='center')
                plt.axis('off')
                buffer = io.BytesIO()
                plt.savefig(buffer, format='png', bbox_inches='tight', dpi=50)
                plt.close()
                img_data = buffer.getvalue()

            img_base64 = base64.b64encode(img_data).decode('utf-8')
            return f"data:image/png;base64,{img_base64}"

        local_scope['_save_plot_to_base64'] = _save_plot_to_base64
        
        try:
            exec(analysis_code, {"__builtins__": {}}, local_scope)
            
            if 'final_answer' in local_scope:
                return local_scope['final_answer']
            else:
                raise ValueError("Generated code did not produce a 'final_answer' variable.")

        except Exception as e:
            logger.error(f"Error executing LLM-generated code: {e}")
            return await self._fallback_analysis(questions, df)

    async def _fallback_analysis(self, questions: str, df: Optional[pd.DataFrame]) -> List[Any]:
        """
        Fallback for when LLM-generated code fails.
        """
        self.llm_provider.metrics['fallback_used'] += 1
        logger.warning("Falling back to a basic analysis.")
        
        fallback_text = f"Fallback
